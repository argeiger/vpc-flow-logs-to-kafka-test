input {
   s3 {
      access_key_id => "${ACCESS_KEY_ID}"
      secret_access_key => "${SECRET_ACCESS_KEY}"
      bucket => "${COS_BUCKET}"
      endpoint => "https://${COS_ENDPOINT}"
      backup_to_bucket => "${COS_BACKUP_BUCKET}"
      delete => true
      watch_for_new_files => false
   }
}

filter {
   json {
     source => "message"
     remove_field => ["message"]
     remove_field => ["event"]
     remove_field => ["@timestamp"]
     remove_field => ["@version"]
     skip_on_invalid_json => true
   }
   split { field => "[flow_logs]" }
   mutate { remove_field => ["@timestamp", "@version"] }
}

output {
   stdout {}
   kafka {
      codec => json
      bootstrap_servers => "${BOOTSTRAP_SERVERS}"
      topic_id => "${KAFKA_TOPIC}"
      sasl_mechanism => "PLAIN"
      security_protocol => "SASL_SSL"
      sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username='token' password='${API_KEY}';"
   }
}
